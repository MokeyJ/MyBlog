### http/1.0 缺点

`http/1.0` 版本主要的缺点是，每个 `TCP` 连接只能发送一个请求，发送数据完毕，连接就关闭，如果还需要请求其他资源，就必须再新建一个连接

为了解决这个问题，有些浏览器在请求的时候，使用了一个非标准的 `Connection` 字段：

```js
Connection: keep-alive
```

这个字段要求服务器不关闭 `TCP` 连接，以便其他请求复用，服务器同样回应这个字段：

```js
Connection: keep-alive
```


### http/1.1


#### 持久连接

`1.1` 版本的最大的变化，就是引入了持久连接（`persistent connection`），即 `TCP` 连接默认不关闭，可以被多个请求复用，不用声明 ```Connection: keep-alive```

客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接，不过，规范的做法是，客户端在最后一个请求的时候，发送 ```Connention: close```，明确要求服务器关闭 `TCP` 连接

HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。

#### 缓存

在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略

#### 节约带宽

HTTP/1.1加入了一个新的状态码100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。100 (Continue) 状态代码的使用，允许客户端在发request消息body之前先用request header试探一下server，看server要不要接收request body，再决定要不要发request body。

这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。

另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。HTTP/1.1支持文件断点续传，RANGE:bytes，HTTP/1.0每次传送文件都是从文件头开始，即0字节处开始。RANGE:bytes=XXXX表示要求服务器从文件XXXX字节处开始传送，断点续传。

#### 管道机制

`1.1` 版本还引入了管道机制（`pipelining`），即在同一个 `TCP` 连接里面，客户端可以同时发送多个请求

例如客户端需要请求两个资源。以前的做法是，在同一个 `TCP` 连接里面，先发送 `A` 请求，然后等待服务器做出回应，收到后再发出 `B` 请求。管道机制则是允许浏览器同时发出 `A` 请求和 `B` 请求，但是服务器还是按照顺序，先回应 A 请求，完成后再回应 `B` 请求

#### host字段

在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。

 HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。此外，服务器应该接受以绝对路径标记的资源请求。

#### content-length字段


#### 分块传输编码

分块传输编码（Chunked transfer encoding）是超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分。分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供。通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块发送，这样服务器可以发送数据而不需要预先知道发送内容的总大小。通常数据块的大小是一致的，但也不总是这种情况。

#### http/1.1 缺点

虽然 `1.1` 版允许复用 `TCP` 连接，但是同一个 `TCP` 连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为"队头堵塞"（`Head-of-line blocking`）

为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接


## http/2

主要涉及二进制帧，多路复用，请求优先级，流量控制，服务器端推送以及首部压缩等新改进

#### 二进制协议

`http/1.1` 版本的头信息肯定是文本（`ASCII` 编码），数据体可以是文本，也可以是二进制，`http/2` 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为 "帧"（`frame`），头信息帧 和 数据帧

在二进制分帧层中， `HTTP/2` 会将所有传输的信息分割为更小的消息和帧（`frame`）,并对它们采用二进制格式的编码 ，其中 `HTTP1.x` 的首部信息会被封装到 `HEADER frame`，而相应的 `Request Body` 则封装到 `DATA frame` 里面

`HTTP/2` 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流

总结：

* 单连接多资源的方式，减少服务端的链接压力,内存占用更少,连接吞吐量更大

* 由于 `TCP` 连接的减少而使网络拥塞状况得以改善，同时慢启动时间的减少,使拥塞和丢包恢复速度更快

#### 多路复用

`http/2` 复用 `TCP` 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"

例如在一个 `TCP` 连接里面，服务器同时收到了 `A` 请求和 `B` 请求，于是先回应 `A` 请求，结果发现处理过程非常耗时，于是就发送 `A` 请求已经处理好的部分， 接着回应 `B` 请求，完成后，再发送 `A` 请求剩下的部分

这样双向的、实时的通信，就叫做多工（`Multiplexing`）


#### 数据流（连接共享）

因为 `http/2` 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应

`http/2` 将每个请求或回应的所有数据包，称为一个数据流（`stream`）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流 `ID`，用来区分它属于哪个数据流

另外还规定，客户端发出的数据流，`ID` 一律为奇数，服务器发出的，`ID` 为偶数

数据流发送到一半的时候，客户端和服务器都可以发送信号（`RST_STREAM` 帧），取消这个数据流。`1.1` 版取消数据流的唯一方法，就是关闭 `TCP` 连接。这就是说，`http/2` 可以取消某一次请求，同时保证 `TCP` 连接还打开着，可以被其他请求使用

`http/2` 里的每个 `stream` 都可以设置又优先级（`Priority`）和依赖（`Dependency`）。优先级高的 `stream` 会被 `server` 优先处理和返回给客户端，`stream` 还可以依赖其它的 `sub streams`（优先级和依赖都是可以动态调整的）

客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应


#### 头信息压缩

`http` 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如 `Cookie` 和 `User Agent`，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度

`http/2` 对这一点做了优化，使用了专门为首部压缩而设计的 [HPACK](http://http2.github.io/http2-spec/compression.html) 算法，引入了头信息压缩机制（`header compression`）。一方面，头信息使用 `gzip` 或 `compress` 压缩后再发送

另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了


#### 服务器推送

`http/2` 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（`server push`）

常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析 `html` 源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了
